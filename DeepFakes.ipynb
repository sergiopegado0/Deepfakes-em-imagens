{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODqdDk31XjKVtNHiphBzDM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiopegado0/Deepfakes-em-imagens/blob/main/DeepFakes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNbSlZfb5Mub",
        "outputId": "64b5d179-60ab-423a-a7d0-5cd4222dc860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yV-4RBh4EQQ",
        "outputId": "235ad540-d1e3-473e-e0a7-e91af85ffcf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treinamento: 10\n",
            "Tamanho do conjunto de teste: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Definir transformações\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Carregar dataset completo\n",
        "dataset = ImageFolder(root='/content/drive/MyDrive/Datasets', transform=transform)\n",
        "\n",
        "# Definir tamanhos dos conjuntos de treinamento e teste\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Criar DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "print(f'Tamanho do conjunto de treinamento: {len(train_dataset)}')\n",
        "print(f'Tamanho do conjunto de teste: {len(test_dataset)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#REDE NEURAL CNN\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)  # 2 classes: real e deepfake\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n"
      ],
      "metadata": {
        "id": "V2G4Jp5x4MrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinamento\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(10):  # Número de épocas\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Época {epoch+1}, Perda Média: {running_loss/len(train_loader)}')\n",
        "\n",
        "print('Treinamento concluído!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yw7k1wK4QAJ",
        "outputId": "21c82ee4-a8e5-46e1-e3e2-c18719243a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Perda Média: 0.687640368938446\n",
            "Época 2, Perda Média: 0.6264840960502625\n",
            "Época 3, Perda Média: 0.5714696049690247\n",
            "Época 4, Perda Média: 0.541502058506012\n",
            "Época 5, Perda Média: 0.5288042426109314\n",
            "Época 6, Perda Média: 0.5199735164642334\n",
            "Época 7, Perda Média: 0.5040746927261353\n",
            "Época 8, Perda Média: 0.478665292263031\n",
            "Época 9, Perda Média: 0.45065364241600037\n",
            "Época 10, Perda Média: 0.42881888151168823\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Carregar imagens reais e deepfake\n",
        "real_path = \"/content/drive/MyDrive/Datasets/1_real\"\n",
        "deepfake_path = \"/content/drive/MyDrive/Datasets/2_deepfake\"\n",
        "\n",
        "# Função para carregar imagens\n",
        "def load_images(path):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = Image.open(os.path.join(path, filename)).convert('RGB') # Convert to RGB\n",
        "        img_tensor = transform(img)\n",
        "        images.append(img_tensor)\n",
        "    return images\n",
        "\n",
        "real_images = load_images(real_path)\n",
        "deepfake_images = load_images(deepfake_path)\n",
        "\n",
        "# Comparar cada imagem real com todas as deepfake\n",
        "model.eval()\n",
        "correct_real = 0\n",
        "total_real = len(real_images) * len(deepfake_images)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for real_img in real_images:\n",
        "        for fake_img in deepfake_images:\n",
        "            # Remove the extra unsqueeze(0) - the tensors are already batched correctly\n",
        "            # real_img = real_img.unsqueeze(0)\n",
        "            # fake_img = fake_img.unsqueeze(0)\n",
        "            real_output = model(real_img.unsqueeze(0)) # Add batch dimension here instead\n",
        "            fake_output = model(fake_img.unsqueeze(0)) # Add batch dimension here instead\n",
        "            if torch.argmax(real_output) == 0:\n",
        "                correct_real += 1\n",
        "\n",
        "print(f'Precisão na detecção de imagens reais: {100 * correct_real / total_real:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MZ98uGt4Rwu",
        "outputId": "a84c0243-fbac-4af5-965a-d8fb144820c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão na detecção de imagens reais: 25.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar a precisão do modelo em detectar imagens deepfake.\n",
        "correct_fake = 0\n",
        "total_fake = len(real_images) * len(deepfake_images)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for fake_img in deepfake_images:\n",
        "        for real_img in real_images:\n",
        "            # Remove the extra unsqueeze(0) - the tensors are already batched correctly\n",
        "            # real_img = real_img.unsqueeze(0)  # Adicionar dimensão de batch\n",
        "            # fake_img = fake_img.unsqueeze(0)  # Adicionar dimensão de batch\n",
        "\n",
        "            # The images are already in the correct format [C, H, W]\n",
        "            # We just need to add the batch dimension using unsqueeze(0)\n",
        "            real_output = model(real_img.unsqueeze(0))\n",
        "            fake_output = model(fake_img.unsqueeze(0))\n",
        "\n",
        "            if torch.argmax(fake_output) == 1:\n",
        "                correct_fake += 1\n",
        "\n",
        "print(f'Precisão na detecção de imagens deepfake: {100 * correct_fake / total_fake:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBdMk0fW4Tax",
        "outputId": "d95cade3-2c63-4b16-a994-53f742106a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão na detecção de imagens deepfake: 90.91%\n"
          ]
        }
      ]
    }
  ]
}